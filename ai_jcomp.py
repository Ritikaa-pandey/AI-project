# -*- coding: utf-8 -*-
"""AI_Jcomp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FaktK16Bfh5qJXac5XTblRFL85y7b45e

Importing Libraries
"""

import matplotlib   # data visualization library in Python
from keras.models import load_model  # keras DL framework for training neural network
from keras.preprocessing import image  # image data preprocessing and augmentation
import numpy as np  # numerical and mathemtaical operations in python
import cv2

"""Mounting Google Drive for extracting Dataset"""

from google.colab import drive # to get to our dataset uploaded at drive
drive.mount("/content/gdrive")

# Commented out IPython magic to ensure Python compatibility.
from PIL import Image as pil_image # used to deal with images
import matplotlib.pyplot as plt # used for visualisation
# %matplotlib inline
# enables the drawing from matplotlib

from keras import backend as K # provides building block for developing dlmodels
import tensorflow as tf # dl applications

from keras.preprocessing.image import ImageDataGenerator # used to receive new variation of image at each epoch

"""Generating/Normalizing Image"""

image_gen = ImageDataGenerator(rotation_range=30,
                              width_shift_range=0.1,
                              height_shift_range=0.1,
                              rescale=1/255,
                              shear_range=0.2,
                              zoom_range=0.2,
                              horizontal_flip=True,
                              fill_mode='nearest')

# in this we try to make all our images similar so that the model can be trained on it

image_shape=(150, 150, 3)

from keras.models import Sequential
from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D

# dropout - to reduce the overfitting of the neural networks
# activation - applies activation function to the output
# dense - layer in which each neuron is deeply connected to each other
# MaxPooling2D is a pooling or max pooling operation which calculates the largest or maximum value in every patch and the feature map.

"""Using Sequential model"""

# we use sequential model when there is a single input and a single output
model = Sequential()

"""Trying Out with different Filters"""

# max pooling - calculates the largest or maximum value in every patch and the feature map
# relu - the output of one is the input of the other, if the output is positive otherwise output will be zero

# kernel_size - Limiting the number of parameters, we are limiting the number of unrelated features possible.
# filters - 32 and 64 are the number of features we are extracting

model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(150, 150, 3), activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(150, 150, 3), activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(filters=64, kernel_size=(3, 3), input_shape=(150, 150, 3), activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(150, 150, 3), activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

# to get the final shape of our 3d image
model.output_shape

"""Flattening out the Image"""

# converting the image into 1d image and getting its shape
model.add(Flatten())

model.output_shape # the final output size of the 1D array (7*7*32)

"""Trying out different Activations with Varying Densities"""

model.add(Dense(128))
model.add(Activation('relu'))

model.add(Dropout(0.5))

model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
             optimizer='Adam',
             metrics=['accuracy'])
model.save_weights('model1.h5')

# The binary_crossentropy will calculate the crossentropy loss between the predicted classes and the true classes.
# Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models.Gradient Descent algorithm The king of all the optimizers and it's very fast, robust, and flexible.

"""Summary of our model"""

model.summary()

batch_size=5

"""Importing train test images in Binary class mode"""

train_image_gen=image_gen.flow_from_directory('/content/gdrive/My Drive/teeth_dataset/train',
                                             target_size=image_shape[:2],
                                             batch_size=batch_size,
                                             class_mode='binary')

test_image_gen=image_gen.flow_from_directory('/content/gdrive/My Drive/teeth_dataset/test',
                                             target_size=image_shape[:2],
                                             batch_size=batch_size,
                                             class_mode='binary')

train_image_gen.class_indices

test_image_gen.class_indices

import warnings
warnings.filterwarnings('ignore')

"""Training the model with 75 epochs and 10 steps per epoch"""

results = model.fit_generator(train_image_gen,
                              epochs=75,
                             steps_per_epoch=10,
                             validation_data=test_image_gen,
                             validation_steps=12)

plt.plot(results.history['accuracy'])
plt.plot(results.history['loss'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('loss')
plt.legend(['Accuracy', 'Loss'], loc='upper left')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

"""Predicting if its healthy or not, by then if the predict>0.5, its healthy else its not"""

from keras.preprocessing import image
import numpy as np
def get_res(path):
    raw_img = tf.keras.utils.load_img(path, target_size=(150, 150))
    raw_img = tf.keras.utils.img_to_array(raw_img)
    raw_img = np.expand_dims(raw_img, axis=0)
    raw_img = raw_img / 255
    predict = model.predict(raw_img)
    plt.imshow(cv2.imread(path))
    if predict >= 0.5:
        text = "Healthy tooth"
    elif 0.25 <= predict <= 0.45:
        text = "Mild cavity on teeth"
    else:
        text = "Cavity infected tooth"
    plt.show()
    print(text)

"""Giving the path and testing on random image"""

# path='/content/gdrive/My Drive/teeth_dataset/test/no-caries/nc10.jpg'
path='/content/cav11.jpg'

get_res(path)